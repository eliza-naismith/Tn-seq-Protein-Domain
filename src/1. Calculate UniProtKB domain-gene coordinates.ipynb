{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate UniProtKB domain-gene coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This script matches the positions of UniProtKB domains/regions within each protein, to the corresponding genomic coordinates of the gene the protein is encoded on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The UniProtKB domains/regions dataset are downloaded from:  \n",
    "Mycobacterium bovis: https://www.uniprot.org/uniprotkb?query=%28taxonomy_id%3A233413%29  \n",
    "Mycobacterium tuberculosis: https://www.uniprot.org/uniprotkb?query=%28taxonomy_id%3A83332%29\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gffpandas.gffpandas as gffpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read in the corresponding UniProtKB domain/region dataset and gene assembly GFF3, depending on the _Mycobacterium_ species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Mycobacterium bovis:\n",
    "uniprotkb_file = '../data/Mycobacterium bovis/Mbovis_uniprotkb_organism_id_233413_2024_06_02.xlsx'\n",
    "gene_assembly_file = '../data/Mycobacterium bovis/LT708304 gene assembly.gff3'\n",
    "gff3_header = 'LT708304.1 1 4349904'\n",
    "output_gff3_file = '../data/Mycobacterium bovis/LT708304 UniProtKB domain assembly.gff3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Mycobacterium tuberculosis:\n",
    "uniprotkb_file = '../data/Mycobacterium tuberculosis/Mtuberculosis_domains_uniprotkb_organism_id_83332_2024_06_24.xlsx'\n",
    "gene_assembly_file = '../data/Mycobacterium tuberculosis/NC_018143.1 gene assembly updated.gff3'\n",
    "gff3_header = 'NC_018143.1 1 4411708'\n",
    "output_gff3_file = '../data/Mycobacterium tuberculosis/NC_018143.1 UniProtKB domain assembly.gff3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/styles/stylesheet.py:241: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "uniprot_df = pd.read_excel(uniprotkb_file)\n",
    "gene_gff = gffpd.read_gff3(gene_assembly_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any rows without a gene_locus, as these cannot be matched to the GFF3 gene assemblies. Also remove any genes that have no domains/regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows without ordered locus gene names\n",
    "uniprot_df = uniprot_df[uniprot_df['Gene Names (ordered locus)'].notna()]\n",
    "\n",
    "# Remove rows with no domain and no region information\n",
    "uniprot_df.dropna(subset = ['Domain [FT]', 'Region'], how = 'all', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a seperate dictionary for data associated with domains and data associated with regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seperate dictionaries of gene locus names with each associated domain or associated region.\n",
    "gene_domain_dict = {}\n",
    "gene_region_dict = {}\n",
    "\n",
    "for index, row in uniprot_df.iterrows():\n",
    "    # Extract gene locus, domain, and region information:\n",
    "    gene = row['Gene Names (ordered locus)']\n",
    "    domains = row['Domain [FT]']\n",
    "    regions = row['Region']\n",
    "\n",
    "    # If there are associated domains:\n",
    "    if pd.notna(domains):\n",
    "        # Split the domains up into seperate values in a list\n",
    "        for domain in domains.split('DOMAIN '):\n",
    "            domain_list = ['DOMAIN; /' + domain.strip() for domain in domains.split('DOMAIN ') if domain.strip()]\n",
    "            # Save under the gene locus name in the dictionary\n",
    "            gene_domain_dict[gene] = domain_list\n",
    "\n",
    "    # If there are associated regions:\n",
    "    if pd.notna(regions):\n",
    "        # Split the domains up into seperate values in a list\n",
    "        for region in regions.split('REGION '):\n",
    "            region_list = ['REGION; /' + region.strip() for region in regions.split('REGION ') if region.strip()]\n",
    "            # Save under the gene locus name in the dictionary\n",
    "            gene_region_dict[gene] = region_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the gene and region dictionaries into dataframes, and merge into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary into a dataframe\n",
    "domain_df = pd.DataFrame(gene_domain_dict.items(), columns = ['locus_tag', 'Feature'])\n",
    "region_df = pd.DataFrame(gene_region_dict.items(), columns = ['locus_tag', 'Feature'])\n",
    "\n",
    "# Modify the dataframes\n",
    "# Create an individual row for each domain\n",
    "domain_df = domain_df.explode('Feature')\n",
    "region_df = region_df.explode('Feature')\n",
    "\n",
    "# Reset index so that each row is individually indexed\n",
    "domain_df.reset_index(drop = True, inplace = True)\n",
    "region_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into a single feature database\n",
    "feature_df = pd.concat([domain_df, region_df])\n",
    "feature_df = feature_df.explode('Feature')\n",
    "feature_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the dataframe to have amino acid co-ordinates in seperate columns and use regex to clean up domain/region metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the feature column into seperate columns\n",
    "feature_df['feature'] = ''\n",
    "feature_df['amino loc'] = ''\n",
    "feature_df['note'] = ''\n",
    "feature_df['evidence'] = ''\n",
    "\n",
    "feature_df[['feature', 'amino loc', 'note', 'evidence']] = feature_df['Feature'].str.split('; /', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the amino locations column into start & end coords\n",
    "feature_df['amino start'] = ''\n",
    "feature_df['amino end'] = ''\n",
    "\n",
    "for index, row in feature_df.iterrows():\n",
    "    amino_start, amino_end = row['amino loc'].split('..')\n",
    "    feature_df.at[index, 'amino start'] = amino_start\n",
    "    feature_df.at[index, 'amino end'] = amino_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Clean up the note column using regex\n",
    "for index, row in feature_df.iterrows():\n",
    "    note = row['note']\n",
    "    stripped_note = re.sub(r'^note=\"(.+?)(?:\";|\")?$', r'\\1', note)\n",
    "    feature_df.loc[index, 'note'] = stripped_note\n",
    "\n",
    "# Clean up the evidence column using regex\n",
    "for index, row in feature_df.iterrows():\n",
    "    if pd.notna(row['evidence']):\n",
    "        evidence = row['evidence']\n",
    "        stripped_evidence = re.sub(r'^evidence=\"(.+?)(?:\";|\")?$', r'\\1', evidence)\n",
    "        feature_df.loc[index, 'evidence'] = stripped_evidence\n",
    "\n",
    "# Clean up the locus tag to remove unncessary 'RVBD_'\n",
    "feature_df['locus_tag'] = feature_df['locus_tag'].str.replace(r' RVBD_[\\w]*', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns that are no longer needed\n",
    "feature_df = feature_df.drop(columns = ['Feature', 'amino loc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information within the feature dataframe can now be matched with the gene information from the corresponding GFF3 to calculate domain genomic coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for just genes from the GFF3\n",
    "gene_gff = gene_gff.filter_feature_of_type(['gene'])\n",
    "gene_gff_header = gene_gff.header\n",
    "\n",
    "# Convert each individual attribute to its own column\n",
    "gene_df = gene_gff.attributes_to_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets using the locus_tag\n",
    "\n",
    "feature_df['locus_tag'] = feature_df['locus_tag'].str.capitalize()\n",
    "gene_df['locus_tag'] = gene_df['locus_tag'].str.capitalize()\n",
    "\n",
    "merged_df = pd.merge(feature_df, gene_df, on = 'locus_tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the domain coordinates\n",
    "\n",
    "# Ensure all coordinates are numeric\n",
    "merged_df['start'] = merged_df['start'].astype(int)\n",
    "merged_df['end'] = merged_df['end'].astype(int)\n",
    "merged_df['amino start'] = merged_df['amino start'].astype(int)\n",
    "merged_df['amino end'] = merged_df['amino end'].astype(int)\n",
    "\n",
    "# Calculate genomic start co-ordinates, taking into account if the strand is positive or negative\n",
    "for index, row in merged_df.iterrows():\n",
    "    if row['strand'] == '+':\n",
    "        merged_df.loc[index, 'feature start'] = (row['start']+(row['amino start']*3-2)-1)\n",
    "        merged_df.loc[index, 'feature end'] = (row['start']+(row['amino end']*3)-1)\n",
    "    elif row['strand'] == '-':\n",
    "        merged_df.loc[index, 'feature end'] = (row['end']-(row['amino start']*3-2)+1)\n",
    "        merged_df.loc[index, 'feature start'] = (row['end']-(row['amino end']*3)+1)\n",
    "\n",
    "# Ensure correct types\n",
    "merged_df['feature start'] = merged_df['feature start'].astype(int)\n",
    "merged_df['feature end'] = merged_df['feature end'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the merged dataframe of domain & region genomic coordinates into a GFF3 dataframe and export as a GFF3 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an attibrutes column\n",
    "for index, row in merged_df.iterrows():\n",
    "    attribute_str = f\"ID=domain-{row['locus_tag']}_{index+1};Name={row['note']};locus_tag={row['locus_tag']};gene_identifier={row['Name']};evidence={row['evidence']}\"\n",
    "    if pd.isna(row['gene']) == False:\n",
    "        attribute_str += f\";gene={row['gene']}\"\n",
    "    merged_df.at[index, 'attributes'] = attribute_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "col_names = ['seq_id', 'source', 'feature', 'feature start', 'feature end', 'score', 'strand', 'phase', 'attributes']\n",
    "merged_df = merged_df[col_names]\n",
    "\n",
    "merged_df = merged_df.rename(columns = {'feature':'type', 'feature start':'start', 'feature end':'end'})\n",
    "merged_df.loc[merged_df['type'] == 'DOMAIN', 'type'] = 'UniprotKB_Domain'\n",
    "merged_df.loc[merged_df['type'] == 'REGION', 'type'] = 'UniprotKB_Region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the merged dataframe back to a GFF3 dataframe\n",
    "header = f\"##gff-version 3\\n##sequence-region {gff3_header}\\n\"\n",
    "merged_gff_df = gffpd.Gff3DataFrame(input_df=merged_df, input_header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the GFF3 dataframe as a file\n",
    "merged_gff_df.to_gff3(output_gff3_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
