{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pfam CD-search domain-gene coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script takes the output files from the NCBI Pfam CD-search and matches them with the correct genomic coordinates and associated gene names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gffpandas.gffpandas as gffpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, identify the NCBI Pfam CD-search files and gene assembly GFF3, depending on the _Mycobacterium_ species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Mycobacterium bovis:\n",
    "CDsearch_folder = '../data/Mycobacterium bovis/text files from NCBI CD-search'\n",
    "gene_assembly_file = '../data/Mycobacterium bovis/LT708304 gene assembly.gff3'\n",
    "species_id = 'LT708304.1'\n",
    "gff3_header = 'LT708304.1 1 4349904'\n",
    "gff3_output = '../data/Mycobacterium bovis/LT708304 Pfam domain assembly.gff3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Mycobacterium tuberculosis:\n",
    "CDsearch_folder = '../data/Mycobacterium tuberculosis/text files from NCBI CD-search'\n",
    "gene_assembly_file = '../data/Mycobacterium tuberculosis/NC_018143.1 gene assembly updated.gff3'\n",
    "species_id = 'NC_018143.1'\n",
    "gff3_hearder = 'NC_018143.1 1 4411708'\n",
    "gff3_output = '../data/Mycobacterium tuberculosis/NC_018143.1 Pfam domain assembly.gff3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the text file outputs containing the predicted domain locations, and isolate the document names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe containing the columns found in the CDsearch output\n",
    "records_df = pd.DataFrame(columns = ['Name', 'Accession', 'Description', 'Interval', 'E-value', 'seq start'])\n",
    "\n",
    "# Loop through and get all the filenames\n",
    "filenames = []\n",
    "for name in os.listdir(CDsearch_folder):\n",
    "    filename = CDsearch_folder + '/' + str(name)\n",
    "    filenames.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within each file, each entry (row in dataframe) is split across three rows. These 3 rows need to be combined into a single entry, and then split across the columns of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each file...\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Get the start co-ordinate of the segment\n",
    "    coordinates = filename.split(' - ')[1]\n",
    "    start_coordinate = int(coordinates.split(':')[0])\n",
    "\n",
    "    # Loop through the lines\n",
    "    records = []\n",
    "    data_lines = lines[1:]\n",
    "    current_line = 0\n",
    "\n",
    "    # Concatenate each set of 3 lines to create a single record\n",
    "    while current_line < len(data_lines)-2:\n",
    "        record = \"\"\n",
    "        record += data_lines[current_line].strip() + '\\t'\n",
    "        record += data_lines[current_line+1].strip() + '\\t'\n",
    "        record += data_lines[current_line+2].strip() + '\\t' + str(start_coordinate)\n",
    "        records.append(record)\n",
    "        current_line += 3\n",
    "\n",
    "    # Split the record based on tabs and turn into a dataframe\n",
    "    rows = [row.split('\\t') for row in records]\n",
    "    column_names = ['Name', 'Accession', 'Description', 'Interval', 'E-value', 'seq start']\n",
    "    current_df = pd.DataFrame(rows[1:], columns = column_names)\n",
    "\n",
    "    # Concatenate to the exisiting dataframe\n",
    "    records_df = pd.concat([records_df, current_df], ignore_index=True)\n",
    "\n",
    "# Convert numeric columns to appropriate types\n",
    "records_df['seq start'] = pd.to_numeric(records_df['seq start'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the start & end genomic co-ordinates for each domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_df['domain start position'] = 0\n",
    "records_df['domain end position'] = 0\n",
    "\n",
    "# Split the 'Interval' column to get start and end coordinates of each domain within its sequence segment\n",
    "for index, row in records_df.iterrows():\n",
    "    locs = row['Interval'].split('-')\n",
    "    start_position = int(locs[0])\n",
    "    end_position = int(locs[1])\n",
    "    records_df.loc[index, 'domain start position'] = start_position\n",
    "    records_df.loc[index, 'domain end position'] = end_position\n",
    "\n",
    "# Convert to numerics\n",
    "records_df['seq start'] = pd.to_numeric(records_df['seq start'])\n",
    "records_df['domain start position'] = pd.to_numeric(records_df['domain start position'])\n",
    "records_df['domain end position'] = pd.to_numeric(records_df['domain end position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_df['domain start coord'] = 0\n",
    "records_df['domain end coord'] = 0\n",
    "\n",
    "# Calculate the actual genomic start & end coordinates of the domains by taking the coordinates of\n",
    "# the sequence segment into account\n",
    "\n",
    "for index, row in records_df.iterrows():\n",
    "    \n",
    "    # Isolate the original coordinate where the sequence segment begins\n",
    "    seq_start = records_df.loc[index, 'seq start']\n",
    "\n",
    "    # Isolate the positions within that segment where the domain is\n",
    "    domain_start = records_df.loc[index, 'domain start position']\n",
    "    domain_end = records_df.loc[index, 'domain end position']\n",
    "\n",
    "    # Calculate the genomic start and end coordinates of the domain\n",
    "    genomic_start = seq_start + domain_start - 1\n",
    "    genomic_end = seq_start + domain_end - 1\n",
    "\n",
    "    # Update entry\n",
    "    records_df.loc[index, 'domain start coord'] = genomic_start\n",
    "    records_df.loc[index, 'domain end coord'] = genomic_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in gene assembly GFF3 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file\n",
    "gene_gff = gffpd.read_gff3(gene_assembly_file)\n",
    "\n",
    "# Convert each individual attribute to its own column\n",
    "gene_df = gene_gff.attributes_to_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the genomic coordinates of all genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_coords = []\n",
    "gene_info = []\n",
    "\n",
    "# Store the gene coordinates in a tuple\n",
    "for index, row in gene_df.iterrows():\n",
    "    gene_coords.append((row['start'], row['end']))  # Append tuple for current row\n",
    "    gene_info.append((row['start'], row['end'], row['locus_tag'], row['Name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the associated gene name and locus tag for each domain identified using NCBI Pfam CD-search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a position is within a gene\n",
    "def is_within_gene(position, gene_coords):\n",
    "    for start, end in gene_coords:\n",
    "        if start <= position <= end:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to find the associated locus_tag and name with a position\n",
    "def find_gene(position, gene_info):\n",
    "    for start, end, locus_tag, name in gene_info:\n",
    "        if start <= position <= end:\n",
    "            return (locus_tag, name)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_df['associated_gene'] = None\n",
    "\n",
    "outliers = []\n",
    "\n",
    "for index, row in records_df.iterrows():\n",
    "    # Find the midpoint coordinate of the domain\n",
    "    start_coord = int(row['domain start coord'])\n",
    "    end_coord = int(row['domain end coord'])\n",
    "    mid_coord = (start_coord + end_coord)/2\n",
    "\n",
    "    # Find the gene which the midpoint coordinate matches too\n",
    "    if is_within_gene(mid_coord, gene_coords):\n",
    "        gene = find_gene(mid_coord, gene_info)\n",
    "        # Find the associated locus tag and gene name\n",
    "        records_df.at[index, 'associated_locus_tag'] = gene[0]\n",
    "        records_df.at[index, 'associated_gene'] = gene[1]\n",
    "    else:\n",
    "        outliers.append((row['Name'], start_coord, mid_coord, end_coord))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataframe containing domain coordinates and associated genes into a GFF3 Dataframe and export GFF3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the attributes column\n",
    "for index, row in records_df.iterrows():\n",
    "    attribute_str = f\"ID=pfamdomain-{row['associated_locus_tag']}_{index+1};Name={row['Name']};accession={row['Accession']};description={row['Description']};locus_tag={row['associated_locus_tag']};gene_name={row['associated_gene']}\"\n",
    "    records_df.loc[index, 'attributes'] = attribute_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create other fields required for a GFF3\n",
    "records_df['seq_id'] = species_id\n",
    "records_df['source'] = \"Pfam CD-search\"\n",
    "records_df['type'] = \"Pfam_Domain/Family\"\n",
    "records_df['score'] = \".\"\n",
    "records_df['strand'] = \".\"\n",
    "records_df['phase'] = \".\"\n",
    "\n",
    "# Isolate only the necessary 9 columns for a standard GFF3\n",
    "col_names = ['seq_id', 'source', 'type', 'domain start coord', 'domain end coord', 'score', 'strand', 'phase', 'attributes']\n",
    "records_df = records_df[col_names]\n",
    "\n",
    "# Rename the start and end columns to match GFF3 requirements\n",
    "records_df = records_df.rename(columns = {'domain start coord':'start', 'domain end coord':'end'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the merged dataframe back to a GFF3 dataframe\n",
    "header = f\"##gff-version 3\\n##sequence-region {gff3_header}\\n\"\n",
    "records_gff_df = gffpd.Gff3DataFrame(input_df=records_df, input_header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the GFF3 dataframe as a file\n",
    "records_gff_df.to_gff3(gff3_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
